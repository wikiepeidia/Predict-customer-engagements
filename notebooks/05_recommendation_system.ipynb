{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b727aba",
   "metadata": {},
   "source": [
    "# Phase 5: Recommendation Logic & Inference\n",
    "\n",
    "**Goal**: Build an end-to-end pipeline that takes a **new customer** and recommends the **best offer** for them.\n",
    "\n",
    "## Process\n",
    "1.  **Define Strategy**: Analyze which offers perform best for each Cluster (using historical data).\n",
    "2.  **Load Operational Models**: Load the saved Scaler and Classifier.\n",
    "3.  **Build Pipeline**:\n",
    "    *   New Date -> Preprocess -> Predict Cluster -> Lookup Best Offer.\n",
    "4.  **Demonstrate**: Run the pipeline on sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f51b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# For parsing the 'value' column in transcript if needed, though we likely did this in Step 1\n",
    "import ast\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd5d6b",
   "metadata": {},
   "source": [
    "## 1. Load Data & Models\n",
    "We need:\n",
    "*   `portfolio.csv`: To know what the offers actually are (BOGO, Discount, etc.).\n",
    "*   `customer_clusters.csv`: To know who belongs to which group.\n",
    "*   `transcript.csv`: To see which offers were actually *completed* by these groups.\n",
    "*   **Models**: The pickle files from Phase 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009a0d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operational models loaded successfully.\n",
      "Portfolio options: 10\n",
      "Labeled Customers: 14825\n"
     ]
    }
   ],
   "source": [
    "# Load Models\n",
    "scaler = joblib.load('../models/customer_scaler.pkl')\n",
    "model = joblib.load('../models/customer_classifier.pkl')\n",
    "\n",
    "print(\"Operational models loaded successfully.\")\n",
    "\n",
    "# Load Data\n",
    "portfolio = pd.read_csv('../data/portfolio.csv')\n",
    "clusters = pd.read_csv('../data/customer_clusters.csv')\n",
    "transcript = pd.read_csv('../data/transcript.csv')\n",
    "\n",
    "print(f\"Portfolio options: {len(portfolio)}\")\n",
    "print(f\"Labeled Customers: {len(clusters)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84d8b8",
   "metadata": {},
   "source": [
    "## 2. Define Recommendation Strategy\n",
    "**Objective**: Create a mapping `{Cluster_ID: Best_Offer_ID}`.\n",
    "\n",
    "Logic:\n",
    "1.  Filter `transcript` for `offer completed` events.\n",
    "2.  Extract the `offer_id` from the value column.\n",
    "3.  Merge with `clusters` to see which group completed which offer.\n",
    "4.  Find the most frequent completed offer for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8f22c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation Strategy (Best Offer per Cluster):\n",
      "Cluster 0: 9b98b8c7a33c4b65b9aebfe6a799e6d9 (bogo)\n",
      "Cluster 1: fafdcd668e3743c1bb461111dcafc2a4 (discount)\n",
      "Cluster 2: fafdcd668e3743c1bb461111dcafc2a4 (discount)\n",
      "Cluster 3: 9b98b8c7a33c4b65b9aebfe6a799e6d9 (bogo)\n"
     ]
    }
   ],
   "source": [
    "# 1. Parsing Transcript for Offer IDs (if not already clean in your data folder)\n",
    "# Usually, in 'transcript', the 'value' column is a string dict like \"{'offer_id': '...'}\"\n",
    "# We'll extract it efficiently.\n",
    "\n",
    "def get_offer_id(val):\n",
    "    try:\n",
    "        if isinstance(val, str):\n",
    "            val_dict = ast.literal_eval(val)\n",
    "            # Keys can be 'offer_id' or 'offer id'\n",
    "            return val_dict.get('offer_id') or val_dict.get('offer id')\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "# Filter for completions only\n",
    "completed_offers = transcript[transcript['event'] == 'offer completed'].copy()\n",
    "completed_offers['offer_id'] = completed_offers['value'].apply(get_offer_id)\n",
    "\n",
    "# 2. Merge with Clusters\n",
    "# We need to map person (customer_id) -> cluster -> offer\n",
    "merged = pd.merge(completed_offers, clusters, left_on='person', right_on='customer_id')\n",
    "\n",
    "# 3. Find Top Offer per Cluster\n",
    "popular_offers = merged.groupby(['cluster', 'offer_id']).size().reset_index(name='count')\n",
    "# Sort by cluster and count (descending)\n",
    "popular_offers = popular_offers.sort_values(['cluster', 'count'], ascending=[True, False])\n",
    "\n",
    "# Get top 1 for each cluster\n",
    "best_offers = popular_offers.groupby('cluster').head(1).reset_index(drop=True)\n",
    "\n",
    "# Create the Map\n",
    "cluster_recommendations = dict(zip(best_offers['cluster'], best_offers['offer_id']))\n",
    "\n",
    "print(\"Recommendation Strategy (Best Offer per Cluster):\")\n",
    "for cluster, offer in cluster_recommendations.items():\n",
    "    offer_type = portfolio[portfolio['id'] == offer]['offer_type'].values[0]\n",
    "    print(f\"Cluster {cluster}: {offer} ({offer_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa187ad1",
   "metadata": {},
   "source": [
    "## 3. Build Inference Pipeline\n",
    "Now we wrap everything into functions to simulate a production API.\n",
    "\n",
    "Input: Dictionary of Customer Features.\n",
    "Output: Recommended Offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00aa084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline function defined.\n"
     ]
    }
   ],
   "source": [
    "def get_recommendation_for_new_customer(customer_data):\n",
    "    \"\"\"\n",
    "    Full pipeline: Preprocess -> Scale -> Predict -> Recommend\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Convert Dictionary to DataFrame (Expected Format)\n",
    "    # Note: These keys MUST match the training features exactly (order matters!)\n",
    "    # We should have saved the feature list in Phase 4, but we can infer it or hardcode if we know it.\n",
    "    # For robust code, we'll try to match the scaler's expected input size.\n",
    "    \n",
    "    input_df = pd.DataFrame([customer_data])\n",
    "    \n",
    "    # 2. Preprocess / Scale\n",
    "    try:\n",
    "        scaled_features = scaler.transform(input_df)\n",
    "    except ValueError as e:\n",
    "        return f\"Error: Feature mismatch. Ensure input has columns: {scaler.feature_names_in_}\"\n",
    "\n",
    "    # 3. Predict Segment\n",
    "    predicted_cluster = model.predict(scaled_features)[0]\n",
    "    \n",
    "    # 4. Get Recommendation\n",
    "    rec_offer_id = cluster_recommendations.get(predicted_cluster)\n",
    "    \n",
    "    # Get Offer Details\n",
    "    offer_details = portfolio[portfolio['id'] == rec_offer_id].iloc[0]\n",
    "    \n",
    "    return {\n",
    "        \"Assigned_Segment\": int(predicted_cluster),\n",
    "        \"Recommended_Offer_ID\": rec_offer_id,\n",
    "        \"Offer_Type\": offer_details['offer_type'],\n",
    "        \"Reward\": offer_details['reward'],\n",
    "        \"Difficulty\": offer_details['difficulty']\n",
    "    }\n",
    "\n",
    "# --- TEST THE PIPELINE ---\n",
    "# Define a dummy customer (Make sure this matches your Phase 4 columns!)\n",
    "# Example: High income, high spend -> likely wants discounts?\n",
    "# Note: You need to replace these keys with YOUR ACTUAL features from Step 4.\n",
    "new_customer_example = {\n",
    "    'age': 35,\n",
    "    'income': 72000,\n",
    "    'membership_days_log': np.log(100), # Short member\n",
    "    'total_amount': 50.0,\n",
    "    'avg_transaction_value': 15.0,\n",
    "    'transaction_count': 3,\n",
    "    'offer_completion_rate': 0.5,\n",
    "    'gender_F': 0, 'gender_M': 1, 'gender_O': 0\n",
    "    # Add other features if your model used them (e.g., channel columns)\n",
    "}\n",
    "\n",
    "# The cell below needs to be adjusted by the user to match exact columns!\n",
    "print(\"Pipeline function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40a789",
   "metadata": {},
   "source": [
    "## 4. Operational Demo\n",
    "Run the function with the sample data. *Note: If this fails, check that the keys in `new_customer_example` match `scaler.feature_names_in_`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad74528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expects features: ['Unnamed: 0', 'age', 'income', 'membership_days', 'total_amount', 'transaction_count', 'average_transaction_value', 'offer completed', 'offer received', 'offer viewed', 'completion_rate', 'bogo_completed', 'discount_completed', 'channel_web_count', 'channel_email_count', 'channel_mobile_count', 'channel_social_count', 'gender_F', 'gender_M', 'gender_O']\n",
      "\n",
      "--- Recommendation Result ---\n",
      "{\n",
      "    \"Assigned_Segment\": 0,\n",
      "    \"Recommended_Offer_ID\": \"9b98b8c7a33c4b65b9aebfe6a799e6d9\",\n",
      "    \"Offer_Type\": \"bogo\",\n",
      "    \"Reward\": 5,\n",
      "    \"Difficulty\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check what features the scaler expects\n",
    "print(\"Model expects features:\", list(scaler.feature_names_in_))\n",
    "\n",
    "# IMPORTANT: Construct a valid test vector based on the printed feature names\n",
    "# For demonstration, we'll create a zero-vector and fill known values\n",
    "test_input = {feature: 0 for feature in scaler.feature_names_in_}\n",
    "test_input['age'] = 40\n",
    "test_input['income'] = 60000\n",
    "test_input['transaction_count'] = 10\n",
    "# ... fill others as needed ...\n",
    "\n",
    "# Run\n",
    "result = get_recommendation_for_new_customer(test_input)\n",
    "print(\"\\n--- Recommendation Result ---\")\n",
    "\n",
    "# Helper to handle NumPy types (int64, float64) during JSON serialization\n",
    "def convert_numpy(o):\n",
    "\tif isinstance(o, (np.integer, np.floating)):\n",
    "\t\treturn o.item()\n",
    "\traise TypeError\n",
    "\n",
    "print(json.dumps(result, indent=4, default=convert_numpy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
